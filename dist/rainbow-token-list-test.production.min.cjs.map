{"version":3,"file":"rainbow-token-list-test.production.min.cjs","sources":["../src/constants.ts","../src/utils/fetch-repository.ts","../src/utils/isError.ts","../src/lib/parse/parser.ts","../src/lib/parse/contract-map.ts","../src/utils/mapDir.ts","../src/lib/parse/ethereum-lists.ts","../src/lib/load.ts","../src/lib/parse/overrides.ts","../src/lib/parse/svg-icons.ts","../src/lib/parse/token-lists.ts","../src/lib/build.ts","../src/lib/write.ts","../src/index.ts"],"sourcesContent":["import { z } from 'zod';\n\nexport const PRODUCTION = process.env.NODE_ENV === 'production';\n\nexport const CONTRACT_MAP_REPO = 'metamask/eth-contract-metadata';\n\nexport const ETHEREUM_LISTS_REPO = 'ethereum-lists/tokens/tokens/eth';\n\n//\n// Related to Token List and Token Overrides.\n//\nexport const REMOTE_TOKEN_LIST_ENDPOINT =\n  'https://raw.githubusercontent.com/ctjlewis/rainbow-token-list/service-compatibility/src/data/rainbow-token-list.json';\n\nexport const REMOTE_TOKEN_OVERRIDES_ENDPOINT =\n  'https://raw.githubusercontent.com/ctjlewis/rainbow-overrides/master/src/data/rainbow-overrides.json';\n\nexport const TokenListItemSchema = z\n  .string()\n  .url()\n  .nonempty();\n\nexport type TokenListItem = z.infer<typeof TokenListItemSchema>;\nexport const TokenListTypeSchema = z.record(TokenListItemSchema);\nexport type TokenListType = z.infer<typeof TokenListTypeSchema>;\n\nexport const TOKEN_LISTS: TokenListType = {\n  aave: 'https://tokenlist.aave.eth.link',\n  coingecko: 'https://tokens.coingecko.com/uniswap/all.json',\n  dharma: 'https://tokenlist.dharma.eth.link',\n  kleros: 'http://t2crtokens.eth.link',\n  roll: 'https://app.tryroll.com/tokens.json',\n  synthetix: 'https://synths.snx.eth.link',\n  wrapped: 'http://wrapped.tokensoft.eth.link',\n};\n\nexport const TokenListEnumSchema = z.enum([\n  'aave',\n  'coingecko',\n  'dharma',\n  'kleros',\n  'roll',\n  'synthetix',\n  'wrapped',\n]);\nexport type TokenListEnum = z.infer<typeof TokenListEnumSchema>;\n\nexport const SocialSchema = z.object({\n  blog: z.string().optional(),\n  chat: z.string().optional(),\n  discord: z.string().optional(),\n  facebook: z.string().optional(),\n  forum: z.string().optional(),\n  github: z.string().optional(),\n  gitter: z.string().optional(),\n  instagram: z.string().optional(),\n  linkedin: z.string().optional(),\n  medium: z.string().optional(),\n  reddit: z.string().optional(),\n  slack: z.string().optional(),\n  telegram: z.string().optional(),\n  twitter: z.string().optional(),\n  youtube: z.string().optional(),\n});\n\nexport const TokenDeprecationSchema = z.object({\n  new_address: z.string().optional(),\n});\n\nexport const TokenExtensionsSchema = z.object({\n  color: z.string().optional(),\n  isRainbowCurated: z.boolean().optional(),\n  isVerified: z.boolean().optional(),\n  shadowColor: z.string().optional(),\n});\nexport type TokenExtensionsType = z.infer<typeof TokenExtensionsSchema>;\n\nexport const TokenSchema = z.object({\n  address: z.string().regex(/^0x[a-fA-F0-9]{40}$/),\n  chainId: z.number().optional(),\n  decimals: z.number().min(0),\n  deprecation: TokenDeprecationSchema.optional(),\n  extensions: TokenExtensionsSchema.optional(),\n  name: z.string(),\n  social: SocialSchema.optional(),\n  symbol: z.string(),\n  website: z.string().optional(),\n});\n\n/**\n * Raw token data that is loaded from the JSON files.\n */\nexport const RawContractMapTokenSchema = z.object({\n  address: z.string(),\n  decimals: z.union([z.string(), z.number()]),\n  name: z.string(),\n  symbol: z.string(),\n});\n\n/**\n * Raw token data that is loaded from the JSON files.\n */\nexport const RawEthereumListsTokenSchema = z.object({\n  address: z.string().optional(),\n  decimals: z.union([z.string(), z.number()]).optional(),\n  deprecation: TokenDeprecationSchema.optional(),\n  name: z.string().optional(),\n  social: SocialSchema.optional(),\n  symbol: z.string().optional(),\n  website: z.string().optional(),\n});\n\nexport type RawContractMapToken = z.infer<typeof RawContractMapTokenSchema>;\nexport type RawEthereumListsToken = z.infer<typeof RawEthereumListsTokenSchema>;\nexport type Token = z.infer<typeof TokenSchema>;\nexport type TokenSocialMetadata = z.infer<typeof SocialSchema>;\n","import degit from 'degit';\nimport { tmpdir } from 'os';\nimport { resolve } from 'path';\n\nimport { PRODUCTION } from '../constants';\n\n/**\n * Fetch a Git repository and store it in tmpdir.\n *\n * @return {Promise<void>}\n */\nexport const fetchRepository = async (repoUrl: string) => {\n  const tmp = tmpdir();\n  const emitter = degit(repoUrl, {\n    // cache can cause problems, so disable\n    cache: false,\n    // overwrite existing files\n    force: true,\n    // use verbose mode when developing\n    verbose: !PRODUCTION,\n  });\n\n  if (!PRODUCTION) {\n    emitter.on('info', info => console.log(info.message));\n  }\n\n  const userRepo = repoUrl\n    .split('/')\n    .slice(0, 2)\n    .join('/');\n  const extractedAt = resolve(tmp, userRepo);\n\n  console.log(`Fetching ${repoUrl}`);\n  await emitter.clone(extractedAt);\n  console.log('Success.');\n\n  return extractedAt;\n};\n","interface Error {\n  code: any;\n  message: string;\n}\n\nexport const isError = (error: any): error is Error => {\n  return (\n    typeof error.message !== 'undefined' && typeof error.code !== 'undefined'\n  );\n};\n\nexport const formattedError = (error: any) => {\n  return isError(error) ? error.message : error;\n};\n","import fs from 'graceful-fs';\nimport { isPlainObject, isString, mapValues, pick } from 'lodash';\nimport {\n  RawEthereumListsToken,\n  RawEthereumListsTokenSchema,\n  SocialSchema,\n  Token,\n  TokenSchema,\n  TokenDeprecationSchema,\n} from '../../constants';\nimport { formattedError } from '../../utils/isError';\n\n/**\n * Reads and parses a JSON file. Throws an error if the file could not be read\n * or if the JSON is invalid.\n *\n * @param {string} file\n * @return {Promise<T>}\n * @template T\n */\nexport const parseJsonFile = async <T>(file: string): Promise<T> => {\n  try {\n    const json = await fs.promises.readFile(file, 'utf8');\n    return JSON.parse(json);\n  } catch (error) {\n    throw new Error(`Failed to parse file ${file}: ${formattedError(error)}`);\n  }\n};\n\n/**\n * Validate raw token data, by checking if the required values are set and if\n * the decimals are larger than or equal to zero. This will strip any unknown\n * fields and rename the 'decimals' field to 'decimal' for compatibility.\n *\n * @param {RawEthereumListsToken} token\n * @return {boolean}\n */\nexport const validateTokenData = (token: RawEthereumListsToken): Token => {\n  const normalizedTokenData = {\n    ...pick(token, Object.keys(RawEthereumListsTokenSchema.shape)),\n    deprecation: pick(\n      token.deprecation,\n      Object.keys(TokenDeprecationSchema.shape)\n    ),\n    social: pick(token.social, Object.keys(SocialSchema.shape)),\n  };\n\n  const validToken = TokenSchema.parse(normalizedTokenData);\n  const validSocial = SocialSchema.parse(normalizedTokenData.social);\n\n  return {\n    ...validToken,\n    social: validSocial,\n  } as Token;\n};\n\n/**\n * Sort tokens alphabetically by symbol.\n *\n * @param {Token[]} tokens\n * @return {Token[]}\n */\nexport const sortTokens = (tokens: Token[]): Token[] => {\n  return tokens.sort((a, b) => a.symbol.localeCompare(b.symbol));\n};\n\nfunction mapValuesDeep(v: any, callback: any): any {\n  return isPlainObject(v)\n    ? mapValues(v, v => mapValuesDeep(v, callback))\n    : callback(v);\n}\n\n/**\n * Recursively loop through an token's values and `trim()` any values which are\n * strings.\n *\n * @param {Token} token\n * @return {Token}\n */\nexport const deeplyTrimAllTokenStrings = (token: Token): Token => {\n  return mapValuesDeep(token, (v: any) => (isString(v) ? v.trim() : v));\n};\n","import { isEmpty, pick } from 'lodash';\nimport { resolve } from 'path';\nimport {\n  CONTRACT_MAP_REPO,\n  RawContractMapToken,\n  RawContractMapTokenSchema,\n  Token,\n} from '../../constants';\nimport { fetchRepository } from '../../utils/fetch-repository';\nimport { parseJsonFile, validateTokenData } from './parser';\n\n// the JSON file exported by `eth-contract-metadata` is keyed by token contract address\ntype RawContractMap = { [address: string]: RawContractMapToken };\n\nexport default async function parseContractMap(): Promise<Token[]> {\n  // fetch the latest commit from `eth-contract-metadata` repo and save it to disk\n  const extractedAt = await fetchRepository(CONTRACT_MAP_REPO);\n\n  // load contract map JSON file from directory\n  const jsonFile = resolve(extractedAt, 'contract-map.json');\n  const contractMap = await parseJsonFile<RawContractMap>(jsonFile);\n\n  return (\n    Object.keys(contractMap)\n      .map(\n        (address: string): RawContractMapToken => ({\n          ...contractMap[address],\n          address,\n        })\n      )\n      // remove any unknown/undesirable keys from each token object.\n      .map(token => pick(token, Object.keys(RawContractMapTokenSchema.shape)))\n      // remove any tokens from the array if they contain null values for the\n      // keys that we care about.\n      .filter(token => Object.values(token).some(isEmpty))\n      .map(validateTokenData)\n  );\n}\n","import pLimit from 'p-limit';\nimport fs from 'graceful-fs';\nimport { resolve } from 'path';\n\nexport type FileMap<T = any> = (file: string) => Promise<T>;\n\ninterface MapDirArgs<T> {\n  dir: string;\n  fileMap: FileMap<T>;\n  limit?: number;\n}\n\nexport async function mapDir<T>({ dir, fileMap, limit = 10 }: MapDirArgs<T>) {\n  /**\n   * Run in a pool to prevent EMFILE errors in serverless context.\n   */\n  const pool = pLimit(limit);\n  /**\n   * Resolve dir and load files.\n   */\n  dir = resolve(dir);\n  const files = await fs.promises.readdir(dir);\n\n  const resultPromises: (() => Promise<T>)[] = files.map(file => async () =>\n    await fileMap(resolve(dir, file))\n  );\n\n  const results: T[] = await Promise.all(\n    resultPromises.map(resultPromise => pool(async () => await resultPromise()))\n  );\n\n  return results;\n}\n","/**\n * @fileoverview\n * This file uses fs.readdir in a pure JS Git context, so it relies on\n * graceful-fs to prevent EMFILE errors in serverless environments.\n */\n\nimport { filter, matchesProperty, partition } from 'lodash';\n\nimport { parseJsonFile, validateTokenData } from './parser';\nimport { RawEthereumListsToken } from '../../constants';\nimport { ETHEREUM_LISTS_REPO, Token } from '../../constants';\nimport { fetchRepository } from '../../utils/fetch-repository';\nimport { mapDir } from '../../utils/mapDir';\n\n/**\n * Partition tokens array into two categories: unique vs duplicates, according to\n * their token symbol\n *\n * @param {Token[]} tokens\n * @return {Token[][]}\n */\nexport const partitionByUniqueness = (tokens: Token[]): Token[][] => {\n  const [uniqueTokens, duplicateTokens] = partition(tokens, token => {\n    const dups = filter(tokens, ['symbol', token.symbol]);\n    return dups.length === 1;\n  });\n  return [uniqueTokens, duplicateTokens];\n};\n\n/**\n * Finds deprecated tokens and replaces them with the data\n * for the latest version of the token\n *\n * @param {Token[]} tokens\n *\n * @return {Token[]}\n */\nexport function resolveDeprecations(tokens: Token[]): Token[] {\n  return tokens.map(({ deprecation, ...token }: Token) => {\n    return !deprecation?.new_address\n      ? token\n      : tokens.find(matchesProperty('address', deprecation.new_address)) ||\n          token;\n  });\n}\n\n/**\n * Load the token JSON files from directory, and then validate them\n * against our token schema\n *\n * @return {Token[]}\n */\nexport async function parseEthereumListsTokenFiles(\n  extractedAt: string\n): Promise<Token[]> {\n  const fileMap = async (file: string) => {\n    const tokenData = await parseJsonFile<RawEthereumListsToken>(file);\n    return validateTokenData(tokenData);\n  };\n\n  const results: Token[] = await mapDir({ dir: extractedAt, fileMap });\n  return results;\n}\n\n/**\n * Fetch the latest commit from `ethereum-lists/tokens` repo and parse\n * the saved JSON files\n *\n * @return {Token[][]}\n */\nexport default async function parseEthereumLists(): Promise<Token[][]> {\n  const extractedAt = await fetchRepository(ETHEREUM_LISTS_REPO);\n\n  const tokenLists: Token[][] = await parseEthereumListsTokenFiles(extractedAt)\n    .then(resolveDeprecations)\n    .then(partitionByUniqueness);\n\n  return tokenLists;\n}\n","import { map, toLower } from 'lodash';\n\nimport OFFLINE_TOKEN_METADATA from '../data/rainbow-token-list.json';\nimport { OFFLINE_TOKEN_OVERRIDES } from 'rainbow-overrides';\n\nimport {\n  REMOTE_TOKEN_LIST_ENDPOINT,\n  REMOTE_TOKEN_OVERRIDES_ENDPOINT,\n} from '../constants';\nimport fetch from 'node-fetch';\n\ntype TokenMetadata = typeof OFFLINE_TOKEN_METADATA;\n\n/**\n * Get the raw Token List data.\n *\n * @param endpoint The endpoint from which to load the Token List.\n * @param offlineData The data to fallback to in case of network failure.\n * @returns The Token List dataset.\n */\nexport const loadFromEndpoint = async <T>(endpoint: string, offlineData: T) => {\n  console.log('Making request to', endpoint);\n  try {\n    const result = await fetch(endpoint);\n    console.log('REQUEST SUCCEEDED.');\n    return await result.json();\n  } catch (e) {\n    console.log('REQUEST FAILED.', e);\n    return offlineData;\n  }\n};\n\n/**\n * Load the full Token List, including any manual tokens.\n *\n * @param offlineData The data to fallback to in case of network failure.\n * @returns The full Token List.\n */\nexport const loadTokenList = async () => {\n  const tokenData = await loadFromEndpoint(\n    REMOTE_TOKEN_LIST_ENDPOINT,\n    OFFLINE_TOKEN_METADATA\n  );\n\n  const tokens = await tokenListFromData(tokenData);\n  return tokens;\n};\n\n/**\n * Load the Token Overrides List.\n * @returns All token overrides.\n */\nexport const loadTokenOverrides = async (): Promise<any> => {\n  const overrides = loadFromEndpoint(\n    REMOTE_TOKEN_OVERRIDES_ENDPOINT,\n    OFFLINE_TOKEN_OVERRIDES\n  );\n\n  return overrides;\n};\n\n/**\n * Get the Token List from raw metadata.\n *\n * @param tokenData The raw Token List data to process.\n * @returns The Token List.\n */\nexport const tokenListFromData = async (tokenData: TokenMetadata) => {\n  const loadedTokens = map(tokenData.tokens, token => {\n    const { address: rawAddress, decimals, name, symbol, extensions } = token;\n    const address = toLower(rawAddress);\n\n    return {\n      address,\n      decimals,\n      name,\n      symbol,\n      uniqueId: address,\n      ...extensions,\n    };\n  });\n\n  return loadedTokens;\n};\n","import { getAddress } from '@ethersproject/address';\nimport { mapKeys } from 'lodash';\nimport { loadTokenOverrides } from '../load';\n\nexport type OverrideToken = {\n  color?: string;\n  isCurated?: boolean;\n  isVerified?: boolean;\n  name?: string;\n  symbol?: string;\n  shadowColor?: string;\n};\n\ntype OverrideFile = { [address: string]: OverrideToken };\n\nexport default async function parseOverrides(): Promise<OverrideFile> {\n  const overrides = await loadTokenOverrides();\n  // load svg manifest JSON file from directory\n  return mapKeys(overrides, (...args) => {\n    if (args[1] === 'eth') return args[1];\n    return getAddress(args[1]);\n  });\n}\n","/**\n * @fileoverview\n * This file uses fs.readdir in a pure JS Git context, so it relies on\n * graceful-fs to prevent EMFILE errors in serverless environments.\n */\n\nimport { compact, unionBy } from 'lodash';\nimport getSVGColors from 'get-svg-colors';\n\nimport { resolve } from 'path';\nimport { parseJsonFile } from './parser';\n\nimport { fetchRepository } from '../../utils/fetch-repository';\nimport fs from 'graceful-fs';\nimport { FileMap, mapDir } from '../../utils/mapDir';\nimport makeColorMoreChill from 'make-color-more-chill';\n\nexport type SvgToken = {\n  color: string;\n  name?: string;\n  symbol: string;\n};\n\nexport const SVG_ORIGINALS_REPO = 'spothq/cryptocurrency-icons';\nexport const SVG_OVERRIDES_REPO =\n  'mikedemarais/react-coin-icon/assets/overrides';\n\nasync function parseOriginalSVGIcons() {\n  // fetch the latest commit from `spothq/cryptocurrency-icons` repo and save it to disk\n  const extractedAt = await fetchRepository(SVG_ORIGINALS_REPO);\n  // load svg manifest JSON file from directory\n  const jsonFile = resolve(extractedAt, 'manifest.json');\n  return parseJsonFile<SvgToken[]>(jsonFile);\n}\n\nasync function parseOverrideSVGIcons() {\n  const extractedAt = await fetchRepository(SVG_OVERRIDES_REPO);\n  const fileMap: FileMap = async file => {\n    const svg = await fs.promises.readFile(file, 'utf8');\n\n    // Attempt to get SVG's \"color\" by reading it's first \"fill\"\n    // value (which is usually the icon's background).\n    const fillColor = getSVGColors(svg).fills[0];\n\n    let svgToken = undefined;\n    if (fillColor) {\n      svgToken = {\n        symbol: file.split('.')[0].toUpperCase(),\n        color: makeColorMoreChill(fillColor.hex().toLowerCase()),\n      };\n    } else {\n      console.error(\n        `Couldn't derive color from the \"rainbow override\" SVG file: \\`${file}\\``\n      );\n    }\n\n    return svgToken;\n  };\n\n  const results = await mapDir({\n    dir: extractedAt,\n    fileMap,\n  });\n\n  return compact(results);\n}\n\nexport default async function parseSVGIconTokenFiles(): Promise<SvgToken[]> {\n  const originals = await parseOriginalSVGIcons();\n  const overrides = await parseOverrideSVGIcons();\n\n  return unionBy(originals, overrides, 'symbol');\n}\n","import fetch from 'node-fetch';\nimport { z } from 'zod';\n\nimport {\n  TOKEN_LISTS,\n  TokenListEnum,\n  TokenListEnumSchema,\n} from '../../constants';\n\nexport function reduceArrayToObject(array: any[]) {\n  return array.reduce((item, culm) => Object.assign(culm, item), {});\n}\n\nexport const TokenListStore = z.object({\n  tags: z\n    .any()\n    .array()\n    .optional(),\n  tokens: z\n    .any()\n    .array()\n    .optional(),\n});\nexport type TokenListStoreType = z.infer<typeof TokenListStore>;\nexport const TokenListStoreRecord = z.record(TokenListStore);\nexport type TokenListStoreRecordType = z.infer<typeof TokenListStoreRecord>;\n\nconst omitTokenWithTag = (tokens: any[], tag: string) =>\n  tokens.filter(({ tags = [] }: TokenListStoreType) => !tags.includes(tag));\n\nconst pickTokenWithTag = (tokens: any[], tag: string) =>\n  tokens.filter(({ tags = [] }: TokenListStoreType) => tags.includes(tag));\n\nconst { aave, roll } = TokenListEnumSchema.enum;\n\nexport default async function parseTokenLists() {\n  const listsArray = await Promise.all(\n    TokenListEnumSchema.options.map(\n      async (list: TokenListEnum): Promise<TokenListStoreRecordType> => {\n        return new Promise(async (resolve, reject) =>\n          // fetch the TokenList from remote uri\n          fetch(TOKEN_LISTS[list])\n            .then(res => res.json())\n            .then(({ tags, tokens }) => resolve({ [list]: { tags, tokens } }))\n            .catch(reject)\n        );\n      }\n    )\n  );\n\n  return reduceArrayToObject(\n    listsArray.map((list: any) => {\n      const listName = Object.keys(list)[0];\n      const newList = { ...list };\n\n      if (listName === roll) {\n        newList[roll].tokens = omitTokenWithTag(newList[roll].tokens, 'bases');\n      }\n\n      if (listName === aave) {\n        newList[aave].tokens = [\n          ...pickTokenWithTag(newList[aave].tokens, 'atokenv1'),\n          ...pickTokenWithTag(newList[aave].tokens, 'atokenv2'),\n        ];\n      }\n\n      return newList;\n    })\n  );\n}\n","import {\n  compact,\n  filter,\n  find,\n  keyBy,\n  matchesProperty,\n  merge,\n  pick,\n  some,\n  toLower,\n  uniq,\n} from 'lodash';\n\nimport parseContractMap from './parse/contract-map';\nimport parseEthereumLists from './parse/ethereum-lists';\nimport parseOverrides from './parse/overrides';\nimport parseSVGIconTokenFiles from './parse/svg-icons';\nimport parseTokenLists from './parse/token-lists';\n\nimport { getAddress } from '@ethersproject/address';\nimport { Token, TokenExtensionsType, TokenListEnumSchema } from '../constants';\nimport { deeplyTrimAllTokenStrings, sortTokens } from './parse/parser';\n\nfunction normalizeList(list: any[]) {\n  return keyBy(list, ({ address }) => getAddress(address));\n}\n\nexport async function build(): Promise<Token[]> {\n  /**\n   * Parse all of the data we need for the Token List build process. Run\n   * concurrently, since we do not need to execute in a serverless environment,\n   * but disable this if that changes.\n   */\n  const [\n    rainbowOverrides,\n    contractMapTokens,\n    svgIcons,\n    tokenListTokens,\n    [uniqueEthereumListTokens, duplicateEthereumListTokens],\n  ] = await Promise.all([\n    parseOverrides(),\n    parseContractMap(),\n    parseSVGIconTokenFiles(),\n    parseTokenLists(),\n    parseEthereumLists(),\n  ]).catch(e => {\n    throw new Error(`Could not load all token resources: ${e}`);\n  });\n  // const rainbowOverrides = await parseOverrides();\n  // const contractMapTokens = await parseContractMap();\n  // const svgIcons = await parseSVGIconTokenFiles();\n  // const tokenListTokens = await parseTokenLists();\n  // const [\n  //   uniqueEthereumListTokens,\n  //   duplicateEthereumListTokens,\n  // ] = await parseEthereumLists();\n\n  const { coingecko, ...preferredTokenLists } = tokenListTokens;\n  const sources = {\n    default: [\n      duplicateEthereumListTokens,\n      uniqueEthereumListTokens,\n      contractMapTokens,\n      coingecko.tokens.flat(),\n    ].map(normalizeList),\n    preferred: [\n      Object.values(preferredTokenLists)\n        .map(({ tokens }: any) => tokens)\n        .flat(),\n    ].map(normalizeList),\n  };\n\n  const defaultSources: any = merge({}, ...sources.default);\n  const allKnownTokenAddresses: any = uniq(\n    compact([\n      ...sources.default.map(Object.keys).flat(),\n      ...sources.preferred.map(Object.keys).flat(),\n    ]).map(getAddress)\n  );\n\n  function resolveTokenInfo(tokenAddress: string) {\n    function matchToken({ address }: Token): boolean {\n      return toLower(address) === toLower(tokenAddress);\n    }\n\n    const lists = pick(\n      tokenListTokens,\n      Object.keys(tokenListTokens).filter((list: any) =>\n        some(tokenListTokens[list].tokens, matchToken)\n      )\n    );\n\n    if (Object.keys(lists).length === 1) {\n      return find(lists[Object.keys(lists)[0]].tokens, matchToken);\n    } else if (Object.keys(lists).length > 1) {\n      const listNames = Object.keys(lists);\n      if (listNames.includes(TokenListEnumSchema.enum.synthetix)) {\n        return find(lists.synthetix.tokens, matchToken);\n      } else if (listNames.includes(TokenListEnumSchema.enum.aave)) {\n        return find(lists.aave.tokens, matchToken);\n      } else if (listNames.includes(TokenListEnumSchema.enum.roll)) {\n        return find(lists.roll.tokens, matchToken);\n      } else if (listNames.includes(TokenListEnumSchema.enum.dharma)) {\n        return find(lists.dharma.tokens, matchToken);\n      } else if (listNames.includes(TokenListEnumSchema.enum.kleros)) {\n        return find(lists.kleros.tokens, matchToken);\n      } else if (listNames.includes(TokenListEnumSchema.enum.wrapped)) {\n        return find(lists.wrapped.tokens, matchToken);\n      } else if (listNames.includes(TokenListEnumSchema.enum.coingecko)) {\n        return find(lists.coingecko.tokens, matchToken);\n      }\n    }\n\n    return defaultSources[tokenAddress];\n  }\n\n  function buildTokenList() {\n    return allKnownTokenAddresses.map((tokenAddress: string) => {\n      const token = resolveTokenInfo(tokenAddress);\n      const overrideToken = rainbowOverrides[tokenAddress];\n\n      let { chainId = 1, color, decimals, name, shadowColor, symbol } = token;\n\n      const isVerified = sources.preferred\n        .map(Object.keys)\n        .flat()\n        .includes(tokenAddress);\n\n      if (isVerified) {\n        const logoData = svgIcons.find(item => item.symbol === symbol);\n        color = logoData?.color;\n      }\n\n      const extensions: TokenExtensionsType = {\n        color: overrideToken?.color || color,\n        isRainbowCurated: overrideToken?.isCurated ? true : undefined,\n        isVerified:\n          isVerified || overrideToken?.isCurated\n            ? true\n            : !!overrideToken?.isVerified || undefined,\n        shadowColor: overrideToken?.shadowColor || shadowColor,\n      };\n\n      return deeplyTrimAllTokenStrings({\n        address: tokenAddress,\n        chainId,\n        decimals,\n        name: overrideToken?.name || name,\n        symbol: overrideToken?.symbol || symbol,\n        ...(compact(Object.values(extensions)).length\n          ? { extensions }\n          : undefined),\n      });\n    });\n  }\n\n  const tokens = await sortTokens(buildTokenList());\n\n  console.log(\n    '# of \"isRainbowCurated\" tokens: ',\n    filter(tokens, matchesProperty('extensions.isRainbowCurated', true)).length\n  );\n  console.log(\n    '# of \"isVerified\" tokens: ',\n    filter(tokens, matchesProperty('extensions.isVerified', true)).length\n  );\n\n  return tokens;\n}\n","import mkdirp from 'mkdirp';\nimport fs from 'graceful-fs';\nimport { dirname, resolve } from 'path';\nimport { formattedError, isError } from '../utils/isError';\nimport { build } from './build';\n\n/**\n * Recursively creates the output folder(s) if they do not exist yet.\n *\n * @param {string} location The output file or folder.\n * @return {Promise<void>}\n */\nexport const createOutputFolder = async (location: string): Promise<void> => {\n  const path = dirname(location);\n  try {\n    await fs.promises.access(path);\n  } catch (error) {\n    if (isError(error)) {\n      if (error.code !== 'ENOENT') {\n        throw new Error(\n          `Failed to create output folder: ${formattedError(error)}`\n        );\n      }\n\n      mkdirp.sync(path);\n    }\n  }\n};\n\n/**\n * Write the Rainbow Token List JSON file to process.cwd().\n *\n * @param {Token[]} tokens The tokens to write.\n * @param {string} location The path to the output file.\n *\n * @return {Promise<void>}\n */\nexport const writeToDisk = async (\n  tokens: any,\n  location: string\n): Promise<void> => {\n  const json = JSON.stringify(tokens, null, 2);\n  const outputLocation = resolve(location);\n  await createOutputFolder(outputLocation);\n  console.log('Writing to', outputLocation);\n  return fs.promises.writeFile(outputLocation, json, 'utf8');\n};\n\nexport async function write() {\n  const tokens = await build();\n  await writeToDisk(\n    {\n      name: 'Rainbow Token List',\n      timestamp: new Date().toISOString(),\n      logoURI: 'https://avatars0.githubusercontent.com/u/48327834?s=200&v=4',\n      version: {\n        major: 1,\n        minor: 2,\n        patch: 1,\n      },\n      keywords: ['rainbow'],\n      tokens,\n    },\n    resolve(process.cwd(), 'src/data/rainbow-token-list.json')\n  );\n}\n","#!/usr/bin/env node\n\n/**\n * Disable certificate validation.\n *\n * @see https://nodejs.org/api/cli.html#cli_node_tls_reject_unauthorized_value\n */\n/**\n * Library imports and exports.\n */\nprocess.env.NODE_TLS_REJECT_UNAUTHORIZED = '0';\n/**\n * Make TS definitions available.\n */\n/**\n * Expose as much of the library as possible to consumers.\n */\nexport * from './constants';\nexport * from './lib/build';\nexport * from './lib/load';\nexport * from './lib/write';\nexport * from './lib/parse';\n"],"names":["REMOTE_TOKEN_LIST_ENDPOINT","REMOTE_TOKEN_OVERRIDES_ENDPOINT","TokenListItemSchema","z","string","url","nonempty","TokenListTypeSchema","record","TOKEN_LISTS","aave","coingecko","dharma","kleros","roll","synthetix","wrapped","TokenListEnumSchema","enum","SocialSchema","object","blog","optional","chat","discord","facebook","forum","github","gitter","instagram","linkedin","medium","reddit","slack","telegram","twitter","youtube","TokenDeprecationSchema","new_address","TokenExtensionsSchema","color","isRainbowCurated","boolean","isVerified","shadowColor","TokenSchema","address","regex","chainId","number","decimals","min","deprecation","extensions","name","social","symbol","website","RawContractMapTokenSchema","union","RawEthereumListsTokenSchema","fetchRepository","async","repoUrl","tmp","tmpdir","emitter","degit","cache","force","verbose","userRepo","split","slice","join","extractedAt","resolve","console","log","clone","isError","error","message","code","formattedError","parseJsonFile","file","json","fs","promises","readFile","JSON","parse","Error","validateTokenData","token","normalizedTokenData","pick","Object","keys","shape","sortTokens","tokens","sort","a","b","localeCompare","mapValuesDeep","v","callback","isPlainObject","mapValues","deeplyTrimAllTokenStrings","isString","trim","parseContractMap","jsonFile","contractMap","map","filter","values","some","isEmpty","mapDir","dir","fileMap","limit","pool","pLimit","resultPromises","readdir","Promise","all","resultPromise","partitionByUniqueness","uniqueTokens","duplicateTokens","partition","length","resolveDeprecations","find","matchesProperty","parseEthereumListsTokenFiles","tokenData","parseEthereumLists","then","loadFromEndpoint","endpoint","offlineData","result","fetch","e","loadTokenOverrides","OFFLINE_TOKEN_OVERRIDES","tokenListFromData","rawAddress","toLower","uniqueId","parseOverrides","overrides","mapKeys","args","getAddress","parseSVGIconTokenFiles","originals","parseOriginalSVGIcons","results","svg","fillColor","getSVGColors","fills","svgToken","toUpperCase","makeColorMoreChill","hex","toLowerCase","compact","parseOverrideSVGIcons","unionBy","reduceArrayToObject","array","reduce","item","culm","assign","TokenListStore","tags","any","TokenListStoreRecord","pickTokenWithTag","tag","includes","parseTokenLists","options","list","reject","res","catch","listName","newList","normalizeList","keyBy","build","rainbowOverrides","contractMapTokens","svgIcons","tokenListTokens","uniqueEthereumListTokens","duplicateEthereumListTokens","preferredTokenLists","sources","default","flat","preferred","defaultSources","merge","allKnownTokenAddresses","uniq","tokenAddress","matchToken","lists","listNames","resolveTokenInfo","overrideToken","isCurated","undefined","createOutputFolder","location","path","dirname","access","mkdirp","sync","writeToDisk","stringify","outputLocation","writeFile","process","env","NODE_TLS_REJECT_UNAUTHORIZED","OFFLINE_TOKEN_METADATA","timestamp","Date","toISOString","logoURI","version","major","minor","patch","keywords","cwd"],"mappings":"mmCAWaA,GACX,uHAEWC,GACX,sGAEWC,GAAsBC,IAChCC,SACAC,MACAC,WAGUC,GAAsBJ,IAAEK,OAAON,IAG/BO,GAA6B,CACxCC,KAAM,kCACNC,UAAW,gDACXC,OAAQ,oCACRC,OAAQ,6BACRC,KAAM,sCACNC,UAAW,8BACXC,QAAS,qCAGEC,GAAsBd,IAAEe,KAAK,CACxC,OACA,YACA,SACA,SACA,OACA,YACA,YAIWC,GAAehB,IAAEiB,OAAO,CACnCC,KAAMlB,IAAEC,SAASkB,WACjBC,KAAMpB,IAAEC,SAASkB,WACjBE,QAASrB,IAAEC,SAASkB,WACpBG,SAAUtB,IAAEC,SAASkB,WACrBI,MAAOvB,IAAEC,SAASkB,WAClBK,OAAQxB,IAAEC,SAASkB,WACnBM,OAAQzB,IAAEC,SAASkB,WACnBO,UAAW1B,IAAEC,SAASkB,WACtBQ,SAAU3B,IAAEC,SAASkB,WACrBS,OAAQ5B,IAAEC,SAASkB,WACnBU,OAAQ7B,IAAEC,SAASkB,WACnBW,MAAO9B,IAAEC,SAASkB,WAClBY,SAAU/B,IAAEC,SAASkB,WACrBa,QAAShC,IAAEC,SAASkB,WACpBc,QAASjC,IAAEC,SAASkB,aAGTe,GAAyBlC,IAAEiB,OAAO,CAC7CkB,YAAanC,IAAEC,SAASkB,aAGbiB,GAAwBpC,IAAEiB,OAAO,CAC5CoB,MAAOrC,IAAEC,SAASkB,WAClBmB,iBAAkBtC,IAAEuC,UAAUpB,WAC9BqB,WAAYxC,IAAEuC,UAAUpB,WACxBsB,YAAazC,IAAEC,SAASkB,aAIbuB,GAAc1C,IAAEiB,OAAO,CAClC0B,QAAS3C,IAAEC,SAAS2C,MAAM,uBAC1BC,QAAS7C,IAAE8C,SAAS3B,WACpB4B,SAAU/C,IAAE8C,SAASE,IAAI,GACzBC,YAAaf,GAAuBf,WACpC+B,WAAYd,GAAsBjB,WAClCgC,KAAMnD,IAAEC,SACRmD,OAAQpC,GAAaG,WACrBkC,OAAQrD,IAAEC,SACVqD,QAAStD,IAAEC,SAASkB,aAMToC,GAA4BvD,IAAEiB,OAAO,CAChD0B,QAAS3C,IAAEC,SACX8C,SAAU/C,IAAEwD,MAAM,CAACxD,IAAEC,SAAUD,IAAE8C,WACjCK,KAAMnD,IAAEC,SACRoD,OAAQrD,IAAEC,WAMCwD,GAA8BzD,IAAEiB,OAAO,CAClD0B,QAAS3C,IAAEC,SAASkB,WACpB4B,SAAU/C,IAAEwD,MAAM,CAACxD,IAAEC,SAAUD,IAAE8C,WAAW3B,WAC5C8B,YAAaf,GAAuBf,WACpCgC,KAAMnD,IAAEC,SAASkB,WACjBiC,OAAQpC,GAAaG,WACrBkC,OAAQrD,IAAEC,SAASkB,WACnBmC,QAAStD,IAAEC,SAASkB,aClGTuC,GAAkBC,MAAOC,IACpC,MAAMC,EAAMC,WACNC,EAAUC,UAAMJ,EAAS,CAE7BK,OAAO,EAEPC,OAAO,EAEPC,SAAS,IAOLC,EAAWR,EACdS,MAAM,KACNC,MAAM,EAAG,GACTC,KAAK,KACFC,EAAcC,UAAQZ,EAAKO,GAMjC,OAJAM,QAAQC,IAAI,YAAYf,WAClBG,EAAQa,MAAMJ,GACpBE,QAAQC,IAAI,YAELH,GC/BIK,GAAWC,QAEK,IAAlBA,EAAMC,cAAiD,IAAfD,EAAME,KAI5CC,GAAkBH,GACtBD,GAAQC,GAASA,EAAMC,QAAUD,ECQ7BI,GAAgBvB,MAAUwB,IACrC,IACE,MAAMC,QAAaC,UAAGC,SAASC,SAASJ,EAAM,QAC9C,OAAOK,KAAKC,MAAML,GAClB,MAAON,GACP,MAAM,IAAIY,MAAM,wBAAwBP,MAASF,GAAeH,QAYvDa,GAAqBC,IAChC,MAAMC,EAAsB,IACvBC,UAAKF,EAAOG,OAAOC,KAAKvC,GAA4BwC,QACvDhD,YAAa6C,UACXF,EAAM3C,YACN8C,OAAOC,KAAK9D,GAAuB+D,QAErC7C,OAAQ0C,UAAKF,EAAMxC,OAAQ2C,OAAOC,KAAKhF,GAAaiF,SAMtD,MAAO,IAHYvD,GAAY+C,MAAMI,GAKnCzC,OAJkBpC,GAAayE,MAAMI,EAAoBzC,UAchD8C,GAAcC,GAClBA,EAAOC,MAAK,CAACC,EAAGC,IAAMD,EAAEhD,OAAOkD,cAAcD,EAAEjD,UAGxD,SAASmD,GAAcC,EAAQC,GAC7B,OAAOC,UAAcF,GACjBG,UAAUH,GAAGA,GAAKD,GAAcC,EAAGC,KACnCA,EAASD,SAUFI,GAA6BjB,GACjCY,GAAcZ,GAAQa,GAAYK,UAASL,GAAKA,EAAEM,OAASN,IClErD9C,eAAeqD,KAE5B,MAAMxC,QAAoBd,GJZK,kCIezBuD,EAAWxC,UAAQD,EAAa,qBAChC0C,QAAoBhC,GAA8B+B,GAExD,OACElB,OAAOC,KAAKkB,GACTC,KACExE,QACIuE,EAAYvE,GACfA,QAAAA,MAIHwE,KAAIvB,GAASE,UAAKF,EAAOG,OAAOC,KAAKzC,GAA0B0C,UAG/DmB,QAAOxB,GAASG,OAAOsB,OAAOzB,GAAO0B,KAAKC,aAC1CJ,IAAIxB,ICvBJhC,eAAe6D,IAAUC,IAAEA,EAAGC,QAAEA,EAAOC,MAAEA,EAAQ,KAItD,MAAMC,EAAOC,UAAOF,GAIpBF,EAAMhD,UAAQgD,GACd,MAEMK,SAFczC,UAAGC,SAASyC,QAAQN,IAEWN,KAAIhC,GAAQxB,eACvD+D,EAAQjD,UAAQgD,EAAKtC,MAO7B,aAJ2B6C,QAAQC,IACjCH,EAAeX,KAAIe,GAAiBN,GAAKjE,eAAkBuE,eCPlDC,GAAyBhC,IACpC,MAAOiC,EAAcC,GAAmBC,UAAUnC,GAAQP,GAEjC,IADVwB,UAAOjB,EAAQ,CAAC,SAAUP,EAAMvC,SACjCkF,SAEd,MAAO,CAACH,EAAcC,aAWRG,GAAoBrC,GAClC,OAAOA,EAAOgB,KAAI,EAAGlE,YAAAA,KAAgB2C,KAC3B3C,GAAad,aAEjBgE,EAAOsC,KAAKC,UAAgB,UAAWzF,EAAYd,eADnDyD,IAYDjC,eAAegF,GACpBnE,GAQA,aAD+BgD,GAAO,CAAEC,IAAKjD,EAAakD,QAL1C/D,MAAOwB,IACrB,MAAMyD,QAAkB1D,GAAqCC,GAC7D,OAAOQ,GAAkBiD,MAadjF,eAAekF,KAC5B,MAAMrE,QAAoBd,GNjEO,oCMuEjC,aAJoCiF,GAA6BnE,GAC9DsE,KAAKN,IACLM,KAAKX,w73rBCvDGY,GAAmBpF,MAAUqF,EAAkBC,KAC1DvE,QAAQC,IAAI,oBAAqBqE,GACjC,IACE,MAAME,QAAeC,UAAMH,GAE3B,OADAtE,QAAQC,IAAI,4BACCuE,EAAO9D,OACpB,MAAOgE,GAEP,OADA1E,QAAQC,IAAI,kBAAmByE,GACxBH,IAwBEI,GAAqB1F,SACdoF,GAChBjJ,GACAwJ,2BAYSC,GAAoB5F,MAAOiF,GACjBzB,UAAIyB,EAAUzC,QAAQP,IACzC,MAAQjD,QAAS6G,EAAUzG,SAAEA,EAAQI,KAAEA,EAAIE,OAAEA,EAAMH,WAAEA,GAAe0C,EAC9DjD,EAAU8G,UAAQD,GAExB,MAAO,CACL7G,QAAAA,EACAI,SAAAA,EACAI,KAAAA,EACAE,OAAAA,EACAqG,SAAU/G,KACPO,MC/DMS,eAAegG,KAC5B,MAAMC,QAAkBP,KAExB,OAAOQ,UAAQD,GAAW,IAAIE,IACZ,QAAZA,EAAK,GAAqBA,EAAK,GAC5BC,aAAWD,EAAK,MC+CZnG,eAAeqG,KAC5B,MAAMC,QAzCRtG,iBAEE,MAAMa,QAAoBd,GANM,+BAQ1BuD,EAAWxC,UAAQD,EAAa,iBACtC,OAAOU,GAA0B+B,GAoCTiD,GAClBN,QAlCRjG,iBACE,MAAMa,QAAoBd,GAX1B,iDAkCMyG,QAAgB3C,GAAO,CAC3BC,IAAKjD,EACLkD,QAxBuB/D,MAAMwB,IAC7B,MAAMiF,QAAY/E,UAAGC,SAASC,SAASJ,EAAM,QAIvCkF,EAAYC,UAAaF,GAAKG,MAAM,GAE1C,IAAIC,EAYJ,OAXIH,EACFG,EAAW,CACTnH,OAAQ8B,EAAKd,MAAM,KAAK,GAAGoG,cAC3BpI,MAAOqI,WAAmBL,EAAUM,MAAMC,gBAG5ClG,QAAQI,MACN,iEAAiEK,OAI9DqF,KAQT,OAAOK,UAAQV,GAKSW,GAExB,OAAOC,UAAQd,EAAWL,EAAW,mBC9DvBoB,GAAoBC,GAClC,OAAOA,EAAMC,QAAO,CAACC,EAAMC,IAASrF,OAAOsF,OAAOD,EAAMD,IAAO,UAGpDG,GAAiBtL,IAAEiB,OAAO,CACrCsK,KAAMvL,IACHwL,MACAP,QACA9J,WACHgF,OAAQnG,IACLwL,MACAP,QACA9J,aAGQsK,GAAuBzL,IAAEK,OAAOiL,IAMvCI,GAAmB,CAACvF,EAAewF,IACvCxF,EAAOiB,QAAO,EAAGmE,KAAAA,EAAO,MAA6BA,EAAKK,SAASD,MAE/DpL,KAAEA,GAAII,KAAEA,IAASG,GAAoBC,KAE5B4C,eAAekI,KAe5B,OAAOb,UAdkBhD,QAAQC,IAC/BnH,GAAoBgL,QAAQ3E,KAC1BxD,MAAOoI,GACE,IAAI/D,SAAQrE,MAAOc,EAASuH,IAEjC7C,UAAM7I,GAAYyL,IACfjD,MAAKmD,GAAOA,EAAI7G,SAChB0D,MAAK,EAAGyC,KAAAA,EAAMpF,OAAAA,KAAa1B,EAAQ,CAAEsH,CAACA,GAAO,CAAER,KAAAA,EAAMpF,OAAAA,OACrD+F,MAAMF,SAOJ7E,KAAK4E,IACd,MAAMI,EAAWpG,OAAOC,KAAK+F,GAAM,GAC7BK,EAAU,IAAKL,GAarB,OAXII,IAAaxL,KACfyL,EAAQzL,IAAMwF,OAA0BiG,EAAQzL,IAAMwF,OA5BrDiB,QAAO,EAAGmE,KAAAA,EAAO,OAA8BA,EAAKK,SA4BS,YAG5DO,IAAa5L,KACf6L,EAAQ7L,IAAM4F,OAAS,IAClBuF,GAAiBU,EAAQ7L,IAAM4F,OAAQ,eACvCuF,GAAiBU,EAAQ7L,IAAM4F,OAAQ,cAIvCiG,MC3Cb,SAASC,GAAcN,GACrB,OAAOO,UAAMP,GAAM,UAAGpJ,KAAcoH,aAAWpH,KAG1CgB,eAAe4I,KAMpB,MACEC,EACAC,EACAC,EACAC,GACCC,EAA0BC,UACnB7E,QAAQC,IAAI,CACpB0B,KACA3C,KACAgD,KACA6B,KACAhD,OACCqD,OAAM9C,IACP,MAAM,IAAI1D,MAAM,uCAAuC0D,SAWnD5I,UAAEA,KAAcsM,GAAwBH,EACxCI,EAAU,CACdC,QAAS,CACPH,EACAD,EACAH,EACAjM,EAAU2F,OAAO8G,QACjB9F,IAAIkF,IACNa,UAAW,CACTnH,OAAOsB,OAAOyF,GACX3F,KAAI,EAAGhB,OAAAA,KAAkBA,IACzB8G,QACH9F,IAAIkF,KAGFc,EAAsBC,UAAM,MAAOL,EAAQC,SAC3CK,EAA8BC,UAClCzC,UAAQ,IACHkC,EAAQC,QAAQ7F,IAAIpB,OAAOC,MAAMiH,UACjCF,EAAQG,UAAU/F,IAAIpB,OAAOC,MAAMiH,SACrC9F,IAAI4C,eA+EH5D,QAAeD,GAvCZmH,EAAuBlG,KAAKoG,IACjC,MAAM3H,EAtCV,SAA0B2H,GACxB,SAASC,GAAW7K,QAAEA,IACpB,OAAO8G,UAAQ9G,KAAa8G,UAAQ8D,GAGtC,MAAME,EAAQ3H,UACZ6G,EACA5G,OAAOC,KAAK2G,GAAiBvF,QAAQ2E,GACnCzE,UAAKqF,EAAgBZ,GAAM5F,OAAQqH,MAIvC,GAAkC,IAA9BzH,OAAOC,KAAKyH,GAAOlF,OACrB,OAAOE,UAAKgF,EAAM1H,OAAOC,KAAKyH,GAAO,IAAItH,OAAQqH,GAC5C,GAAIzH,OAAOC,KAAKyH,GAAOlF,OAAS,EAAG,CACxC,MAAMmF,EAAY3H,OAAOC,KAAKyH,GAC9B,GAAIC,EAAU9B,SAAS9K,GAAoBC,KAAKH,WAC9C,OAAO6H,UAAKgF,EAAM7M,UAAUuF,OAAQqH,GAC/B,GAAIE,EAAU9B,SAAS9K,GAAoBC,KAAKR,MACrD,OAAOkI,UAAKgF,EAAMlN,KAAK4F,OAAQqH,GAC1B,GAAIE,EAAU9B,SAAS9K,GAAoBC,KAAKJ,MACrD,OAAO8H,UAAKgF,EAAM9M,KAAKwF,OAAQqH,GAC1B,GAAIE,EAAU9B,SAAS9K,GAAoBC,KAAKN,QACrD,OAAOgI,UAAKgF,EAAMhN,OAAO0F,OAAQqH,GAC5B,GAAIE,EAAU9B,SAAS9K,GAAoBC,KAAKL,QACrD,OAAO+H,UAAKgF,EAAM/M,OAAOyF,OAAQqH,GAC5B,GAAIE,EAAU9B,SAAS9K,GAAoBC,KAAKF,SACrD,OAAO4H,UAAKgF,EAAM5M,QAAQsF,OAAQqH,GAC7B,GAAIE,EAAU9B,SAAS9K,GAAoBC,KAAKP,WACrD,OAAOiI,UAAKgF,EAAMjN,UAAU2F,OAAQqH,GAIxC,OAAOL,EAAeI,GAKNI,CAAiBJ,GACzBK,EAAgBpB,EAAiBe,GAEvC,IAAI1K,QAAEA,EAAU,EAACR,MAAEA,EAAKU,SAAEA,EAAQI,KAAEA,EAAIV,YAAEA,EAAWY,OAAEA,GAAWuC,EAElE,MAAMpD,EAAauK,EAAQG,UACxB/F,IAAIpB,OAAOC,MACXiH,OACArB,SAAS2B,GAER/K,IAEFH,EADiBqK,EAASjE,MAAK0C,GAAQA,EAAK9H,SAAWA,KACrChB,OAGpB,MAAMa,EAAkC,CACtCb,MAAOuL,GAAevL,OAASA,EAC/BC,mBAAkBsL,GAAeC,gBAAmBC,EACpDtL,cACEA,IAAcoL,GAAeC,cAEvBD,GAAepL,iBAAcsL,EACrCrL,YAAamL,GAAenL,aAAeA,GAG7C,OAAOoE,GAA0B,CAC/BlE,QAAS4K,EACT1K,QAAAA,EACAE,SAAAA,EACAI,KAAMyK,GAAezK,MAAQA,EAC7BE,OAAQuK,GAAevK,QAAUA,KAC7BwH,UAAQ9E,OAAOsB,OAAOnE,IAAaqF,OACnC,CAAErF,WAAAA,QACF4K,QAgBV,OATApJ,QAAQC,IACN,mCACAyC,UAAOjB,EAAQuC,UAAgB,+BAA+B,IAAOH,QAEvE7D,QAAQC,IACN,6BACAyC,UAAOjB,EAAQuC,UAAgB,yBAAyB,IAAOH,QAG1DpC,QC3JI4H,GAAqBpK,MAAOqK,IACvC,MAAMC,EAAOC,UAAQF,GACrB,UACQ3I,UAAGC,SAAS6I,OAAOF,GACzB,MAAOnJ,GACP,GAAID,GAAQC,GAAQ,CAClB,GAAmB,WAAfA,EAAME,KACR,MAAM,IAAIU,MACR,mCAAmCT,GAAeH,MAItDsJ,WAAOC,KAAKJ,MAaLK,GAAc3K,MACzBwC,EACA6H,KAEA,MAAM5I,EAAOI,KAAK+I,UAAUpI,EAAQ,KAAM,GACpCqI,EAAiB/J,UAAQuJ,GAG/B,aAFMD,GAAmBS,GACzB9J,QAAQC,IAAI,aAAc6J,GACnBnJ,UAAGC,SAASmJ,UAAUD,EAAgBpJ,EAAM,SCnCrDsJ,QAAQC,IAAIC,6BAA+B,8BbNV,6DAEE,uDAJT,0LSqBQ,yDAEhC,sdFa2BjL,UAC3B,MAAMiF,QAAkBG,GACtBlJ,GACAgP,IAIF,aADqBtF,GAAkBX,gSKIlCjF,iBACL,MAAMwC,QAAeoG,WACf+B,GACJ,CACEnL,KAAM,qBACN2L,WAAW,IAAIC,MAAOC,cACtBC,QAAS,8DACTC,QAAS,CACPC,MAAO,EACPC,MAAO,EACPC,MAAO,GAETC,SAAU,CAAC,WACXnJ,OAAAA,GAEF1B,UAAQiK,QAAQa,MAAO"}